{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>ARABIC DIALECT CLASSIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Using Machine Learning and Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>By: Zahaf Boualem & Rabiai Mehdi Ayoub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IADD Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load the JSON file\n",
    "with open('Data/country/raw_data/IADD_dataset/IADD.json', 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Create lists to store the relevant columns\n",
    "tweets = []\n",
    "regions = []\n",
    "countries = []\n",
    "\n",
    "# Loop through the JSON data and extract the required information\n",
    "for entry in data:\n",
    "    tweets.append(entry['Sentence'])    # Append the tweet (sentence)\n",
    "    regions.append(entry['Region'])     # Append the region\n",
    "    countries.append(entry['Country'])  # Append the country\n",
    "\n",
    "# Create a pandas DataFrame with the required columns\n",
    "IADD = pd.DataFrame({'tweets': tweets, 'region': regions, 'country': countries})\n",
    "\n",
    "# Remove rows where the country is 'NA'\n",
    "IADD = IADD[IADD['country'] != 'NA']\n",
    "\n",
    "# Calculate the number of samples per country\n",
    "counts_by_country = IADD['country'].value_counts()\n",
    "\n",
    "# Display the result\n",
    "print(counts_by_country)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "IADD.to_csv('Data\\country\\csv_data\\IADD_dataset/IADD_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Madar dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the path to the folder containing the files\n",
    "folder_path = \"Data/country/raw_data/MADAR_dataset\"\n",
    "\n",
    "# Initialize a dictionary to store the data for each country\n",
    "country_data = {}\n",
    "\n",
    "# Deductions for common cities to map them to countries\n",
    "city_to_country = {\n",
    "    \"Aleppo\": \"Syria\",\n",
    "    \"Alexandria\": \"Egypt\",\n",
    "    \"Algiers\": \"Algeria\",\n",
    "    \"Amman\": \"Jordan\",\n",
    "    \"Aswan\": \"Egypt\",\n",
    "    \"Baghdad\": \"Iraq\",\n",
    "    \"Basra\": \"Iraq\",\n",
    "    \"Beirut\": \"Lebanon\",\n",
    "    \"Benghazi\": \"Libya\",\n",
    "    \"Cairo\": \"Egypt\",\n",
    "    \"Damascus\": \"Syria\",\n",
    "    \"Doha\": \"Qatar\",\n",
    "    \"Fes\": \"Morocco\",\n",
    "    \"Jeddah\": \"Saudi Arabia\",\n",
    "    \"Jerusalem\": \"Palestine\",\n",
    "    \"Khartoum\": \"Sudan\",\n",
    "    \"Mosul\": \"Iraq\",\n",
    "    \"MSA\": \"MSA\",  # Modern Standard Arabic\n",
    "    \"Muscat\": \"Oman\",\n",
    "    \"Rabat\": \"Morocco\",\n",
    "    \"Riyadh\": \"Saudi Arabia\",\n",
    "    \"Salt\": \"Jordan\",\n",
    "    \"Sfax\": \"Tunisia\",\n",
    "    \"Tripoli\": \"Libya\",\n",
    "    \"Tunis\": \"Tunisia\",\n",
    "}\n",
    "\n",
    "# Loop through all files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    # Check if the file matches the format MADAR.corpus.City\n",
    "    if filename.startswith(\"MADAR.corpus.\") and filename.endswith(\".tsv\"):\n",
    "        # Extract the city name from the file\n",
    "        city = filename.replace(\"MADAR.corpus.\", \"\").replace(\".tsv\", \"\")\n",
    "        \n",
    "        # Deduce the country based on the city name\n",
    "        country = city_to_country.get(city, \"Unknown\")  # Use \"Unknown\" if city is not listed\n",
    "        \n",
    "        # Read the TSV file using pandas\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        city_df = pd.read_csv(file_path, delimiter='\\t')  # Ensure the delimiter matches the TSV format\n",
    "        \n",
    "        # Rename columns and adjust their order\n",
    "        city_df = city_df.rename(columns={\"sent\": \"tweets\", \"lang\": \"province\"})\n",
    "        city_df = city_df[[\"tweets\", \"province\"]]\n",
    "        \n",
    "        # Add the city's data to the dictionary, using the country name as the key\n",
    "        if country not in country_data:\n",
    "            country_data[country] = []\n",
    "        country_data[country].append(city_df)\n",
    "\n",
    "# Create a folder to store CSV files for each country\n",
    "output_folder = \"Data/country/csv_data/MADAR_dataset\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Loop through the data for each country and save it to a CSV file\n",
    "for country, data_list in country_data.items():\n",
    "    country_df = pd.concat(data_list, ignore_index=True)\n",
    "    output_filename = os.path.join(output_folder, f\"{country}_data.csv\")\n",
    "    country_df.to_csv(output_filename, index=False)\n",
    "\n",
    "print(\"CSV files for each country have been successfully created.\")\n",
    "\n",
    "# Now, combine the country-specific CSV files into a final DataFrame\n",
    "# Specify the folder path containing the country_data.csv files\n",
    "folder_path = \"Data/country/csv_data/MADAR_dataset\"\n",
    "\n",
    "# Initialize a list to store the DataFrames from each file\n",
    "dfs = []\n",
    "\n",
    "# Loop through all files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    # Check if the file matches the format country_data.csv\n",
    "    if filename.endswith(\"_data.csv\"):\n",
    "        # Extract the country name from the file\n",
    "        country = filename.replace(\"_data.csv\", \"\")\n",
    "        \n",
    "        # Read the CSV file using pandas\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        country_df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Add a \"country\" column based on the file name\n",
    "        country_df[\"country\"] = country\n",
    "        \n",
    "        # Add the DataFrame to the list\n",
    "        dfs.append(country_df)\n",
    "\n",
    "# Concatenate all DataFrames in the list into a single DataFrame\n",
    "MADAR = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Reorganize the columns according to the required structure\n",
    "MADAR = MADAR[[\"tweets\", \"country\", \"province\"]]\n",
    "\n",
    "# Save the final DataFrame to a CSV file\n",
    "output_filename = os.path.join(folder_path, \"MADAR_data.csv\")\n",
    "MADAR.to_csv(output_filename, index=False)\n",
    "\n",
    "print(f\"The combined CSV file has been successfully created: {output_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Specify the folder path containing the country_data.csv files\n",
    "folder_path = \"Data/country/csv_data/MADAR_dataset\"\n",
    "\n",
    "# Loop through all files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    # Check if the file is in the country_data.csv format and is not the final combined file\n",
    "    if filename.endswith(\"_data.csv\") and filename != \"MADAR_data.csv\":\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        os.remove(file_path)  # Remove the file\n",
    "        print(f\"File deleted: {filename}\")\n",
    "\n",
    "print(\"Deletion of individual country CSV files completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Modify the IADD dataset by renaming columns and dropping the 'region' column\n",
    "IADD = IADD.rename(columns={\"tweets\": \"text\", \"country\": \"dialect\"}).drop(\"region\", axis=1)\n",
    "\n",
    "# Modify the MADAR dataset by renaming columns and dropping the 'province' column\n",
    "MADAR = MADAR.rename(columns={\"tweets\": \"text\", \"country\": \"dialect\"}).drop(\"province\", axis=1)\n",
    "\n",
    "# Load the MyData dataset from a CSV file\n",
    "MyData = pd.read_csv(\"Data\\country\\csv_data\\MyData\\MyData.csv\")\n",
    "\n",
    "# Replace the full country names with their respective country codes\n",
    "country_mapping = {\n",
    "    \"United Arab Emirates\": \"AE\",\n",
    "    \"Bahrain\": \"BH\",\n",
    "    \"Algeria\": \"DZ\",\n",
    "    \"Egypt\": \"EG\",\n",
    "    \"Iraq\": \"IQ\",\n",
    "    \"Jordan\": \"JO\",\n",
    "    \"Kuwait\": \"KW\",\n",
    "    \"Lebanon\": \"LB\",\n",
    "    \"Libya\": \"LY\",\n",
    "    \"Morocco\": \"MA\",\n",
    "    \"Modern Standard Arabic\": \"MSA\",\n",
    "    \"Oman\": \"OM\",\n",
    "    \"Palestine\": \"PL\",\n",
    "    \"Qatar\": \"QA\",\n",
    "    \"Saudi Arabia\": \"SA\",\n",
    "    \"Sudan\": \"SD\",\n",
    "    \"Syria\": \"SY\",\n",
    "    \"Tunisia\": \"TN\",\n",
    "    \"Yemen\": \"YE\"\n",
    "}\n",
    "\n",
    "# Map the country names to their respective codes in the IADD dataset\n",
    "IADD[\"dialect\"] = IADD[\"dialect\"].map(country_mapping)\n",
    "\n",
    "# Save the updated IADD dataset to a new CSV file\n",
    "output1_path = \"Data/country/csv_data/IADD_dataset/IADD_data.csv\"\n",
    "IADD.to_csv(output1_path, index=False)\n",
    "\n",
    "# Map the country names to their respective codes in the MADAR dataset\n",
    "MADAR[\"dialect\"] = MADAR[\"dialect\"].map(country_mapping)\n",
    "\n",
    "# Save the updated MADAR dataset to a new CSV file\n",
    "output2_path = \"Data\\country\\csv_data\\MADAR_dataset\\MADAR_data.csv\"\n",
    "MADAR.to_csv(output2_path, index=False)\n",
    "\n",
    "# Count the number of samples per country (dialect) in each dataset\n",
    "IADD_count = IADD.groupby(\"dialect\")[\"text\"].count().reset_index()\n",
    "MADAR_count = MADAR.groupby(\"dialect\")[\"text\"].count().reset_index()\n",
    "MyData_count = MyData.groupby(\"dialect\")[\"text\"].count().reset_index()\n",
    "\n",
    "# Display the results\n",
    "print(\"Count for IADD Dataset:\\n\", IADD_count)\n",
    "print(\"\\nCount for MADAR Dataset:\\n\", MADAR_count)\n",
    "print(\"\\nCount for MyData Dataset:\\n\", MyData_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to store the DataFrames from each dataset\n",
    "dfs = [IADD, MADAR, MyData]\n",
    "\n",
    "# Concatenate all DataFrames into a single one\n",
    "all_data = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Exclude samples from the 'YE' (Yemen) dialect\n",
    "all_data = all_data[all_data['dialect'] != 'YE']\n",
    "\n",
    "# Group the DataFrame by dialect and count the number of text samples per group\n",
    "samples_per_country = all_data.groupby(\"dialect\")[\"text\"].count()\n",
    "\n",
    "# Display the number of samples for each country\n",
    "for country, sample_count in samples_per_country.items():\n",
    "    print(f\"There are {sample_count} sample(s) for the country {country}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equilibrage des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the desired number of samples per country\n",
    "desired_sample_count = 21000\n",
    "\n",
    "# Initialize a dictionary to store the balanced DataFrames for each country\n",
    "balanced_data = {}\n",
    "\n",
    "# Iterate through each unique country in the 'all_data' DataFrame\n",
    "for country in all_data['dialect'].unique():\n",
    "    # Select samples for the current country\n",
    "    country_df = all_data[all_data['dialect'] == country]\n",
    "    \n",
    "    # Limit the number of samples to the desired count or the total available, whichever is smaller\n",
    "    balanced_country_df = country_df.sample(min(desired_sample_count, len(country_df)), random_state=42)\n",
    "    \n",
    "    # Add the balanced DataFrame to the dictionary\n",
    "    balanced_data[country] = balanced_country_df\n",
    "\n",
    "# Create a balanced DataFrame by concatenating all the country-specific DataFrames\n",
    "all_data = pd.concat(list(balanced_data.values()), ignore_index=True)\n",
    "\n",
    "# Display the number of samples per country after balancing\n",
    "print(\"Number of samples per country after balancing:\")\n",
    "print(all_data['dialect'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specific dialects to be removed from the DataFrame\n",
    "dialects_to_remove = ['TN', 'BH', 'AE', 'KW']\n",
    "\n",
    "# Remove rows with specific dialects from 'all_data'\n",
    "for dialect in dialects_to_remove:\n",
    "    all_data = all_data[all_data['dialect'] != dialect]\n",
    "\n",
    "# Add corresponding rows from 'MyData' for the specific dialects\n",
    "for dialect in dialects_to_remove:\n",
    "    all_data = pd.concat([all_data, MyData[MyData['dialect'] == dialect]], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing and Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import pyarabic.araby as araby\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import textblob\n",
    "from sklearn import preprocessing\n",
    "\n",
    "arabic_punctuations = '''`÷×؛<>_()*&^%][ـ،/:\"؟.,'{}~¦+|!”…“–ـ'''\n",
    "english_punctuations = string.punctuation\n",
    "punctuations_list = arabic_punctuations + english_punctuations\n",
    "\n",
    "emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           u\"\\U0001f926-\\U0001f937\"\n",
    "                           u\"\\U00010000-\\U0010ffff\"\n",
    "                           u\"\\u2640-\\u2642\"\n",
    "                           u\"\\u2600-\\u2B55\"\n",
    "                           u\"\\u200d\"\n",
    "                           u\"\\u23cf\"\n",
    "                           u\"\\u23e9\"\n",
    "                           u\"\\u231a\"\n",
    "                           u\"\\ufe0f\"  \n",
    "                           u\"\\u3030\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "\n",
    "arabic_diacritics = re.compile(\"\"\"\n",
    "                             ّ    | # Tashdid\n",
    "                             َ    | # Fatha\n",
    "                             ً    | # Tanwin Fath\n",
    "                             ُ    | # Damma\n",
    "                             ٌ    | # Tanwin Damm\n",
    "                             ِ    | # Kasra\n",
    "                             ٍ    | # Tanwin Kasr\n",
    "                             ْ    | # Sukun\n",
    "                             ـ     # Tatwil/Kashida\n",
    "                         \"\"\", re.VERBOSE)\n",
    "\n",
    "\n",
    "def text_cleaning(text):\n",
    "    # Removing Punctuations and Symbols\n",
    "    translator = str.maketrans('', '', punctuations_list)\n",
    "    text = text.translate(translator)\n",
    "    # Remove Emojis\n",
    "    text = emoji_pattern.sub(r'', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def text_normalization(text):\n",
    "    text = re.sub(arabic_diacritics, '', text)\n",
    "    text = araby.strip_diacritics(text)\n",
    "    text = araby.strip_shadda(text)\n",
    "    text = araby.strip_tashkeel(text)\n",
    "\n",
    "    # Remove non-arabic chars\n",
    "    text = re.sub('[%s]' % re.escape(\n",
    "        \"\"\"!\"#$%&'()*+,،-./:;<=>؟?@[\\]^_`{|}~\"\"\"), ' ', text)\n",
    "    text = re.sub('([@A-Za-z0-9_ـــــــــــــ]+)|[^\\w\\s]|#|http\\S+', ' ', text)\n",
    "    text = re.sub(r'\\\\u[A-Za-z0-9\\\\]+', ' ', text)\n",
    "    # Remove repeated letters\n",
    "    text = re.sub(r'[^\\u0600-\\u06FF\\s]', ' ', text)\n",
    "    text = text.strip()\n",
    "    text = re.sub(\"[إأٱآا]\", \"ا\", text)\n",
    "    text = re.sub(\"ى\", \"ي\", text)\n",
    "    text = re.sub(\"ؤ\", \"ء\", text)\n",
    "    text = re.sub(\"ئ\", \"ء\", text)\n",
    "    text = re.sub(\"ة\", \"ه\", text)\n",
    "    text = re.sub(r'(.)\\1+', r'\\1', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def text_preprocessing(dataFrame, text_column):\n",
    "    print(\"[INFO] Starting of pre-processing on the text\")\n",
    "    dataFrame[text_column] = dataFrame[text_column].astype(str)\n",
    "    print(\"[INFO] Starting with text cleaning on the text\")\n",
    "    dataFrame[text_column] = dataFrame[text_column].apply(text_cleaning)\n",
    "    print(\"[INFO] Finishing with text cleaning on the text\")\n",
    "\n",
    "    \n",
    "\n",
    "    # Remove stop words\n",
    "    nltk.download('stopwords')\n",
    "    stop = stopwords.words('arabic')\n",
    "    dataFrame[text_column] = dataFrame[text_column].apply(\n",
    "        lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "\n",
    "    print(\"[INFO] Starting with text normalization on the text\")\n",
    "    dataFrame[text_column] = dataFrame[text_column].apply(text_normalization)\n",
    "    print(\"[INFO] Finishing with text normalization on the text\")\n",
    "\n",
    "    # Lemmatisation\n",
    "    nltk.download('wordnet')\n",
    "    dataFrame[text_column] = dataFrame[text_column].apply(\n",
    "        lambda x: \" \".join([textblob.Word(word).lemmatize() for word in x.split()]))\n",
    "\n",
    "    print(\"[INFO] Finished pre-processing on the text\")\n",
    "    print(\"[INFO] Last step is encoding the class lables\")\n",
    "\n",
    "    return dataFrame\n",
    "\n",
    "\n",
    "def inference_cleaning(text):\n",
    "    text = text_cleaning(text)\n",
    "    text = text_normalization(text)\n",
    "    return text\n",
    "\n",
    "def supprimer_lignes_courtes(df):\n",
    "    # Filtrer les lignes où la longueur du texte est supérieure ou égale à 4 caractères\n",
    "    df = df[df['text'].apply(lambda x: len(str(x)) >= 4)]\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(all_data.info())\n",
    "    processed_dataFrame = text_preprocessing(all_data, 'text')\n",
    "    processed_dataFrame = supprimer_lignes_courtes(processed_dataFrame)\n",
    "    print(processed_dataFrame.info())\n",
    "    # Save preprocessed dataframe to CSV\n",
    "    processed_dataFrame.to_csv('Data\\country\\preprocessed_data/dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the number of samples per country after balancing\n",
    "print(\"Number of samples per country after balancing:\")\n",
    "print(processed_dataFrame['dialect'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrainement et Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Initialize a DataFrame to store the test data\n",
    "test = pd.DataFrame(columns=[\"text\", \"dialect\"])\n",
    "\n",
    "# Iterate through each unique dialect\n",
    "for dialect in processed_dataFrame['dialect'].unique():\n",
    "    # Randomly select 1800 texts for each dialect\n",
    "    selected_texts = processed_dataFrame[processed_dataFrame['dialect'] == dialect].sample(1800)\n",
    "\n",
    "    # Add the selected texts to the test DataFrame\n",
    "    test = pd.concat([test, selected_texts])\n",
    "\n",
    "    # Remove the selected texts from the original DataFrame\n",
    "    processed_dataFrame = processed_dataFrame.drop(selected_texts.index)\n",
    "\n",
    "# The remaining data becomes the training set\n",
    "train = processed_dataFrame\n",
    "\n",
    "# Display the number of samples per dialect in the test DataFrame\n",
    "print(test['dialect'].value_counts())\n",
    "# Display the number of samples per dialect in the training DataFrame\n",
    "print(train['dialect'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NB Classifier (Naive Bayes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train['text']\n",
    "y_train = train['dialect']\n",
    "X_test = test['text']\n",
    "y_test = test['dialect']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "corpus = X_train\n",
    "# Initizalize the vectorizer with max nr words and ngrams (1: single words, 2: two words in a row)\n",
    "vectorizer_tfidf = TfidfVectorizer(ngram_range=(1,2))\n",
    "# Fit the vectorizer to the training data\n",
    "vectorizer_tfidf.fit(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "# Create the Naive Bayes classifier\n",
    "classifier_tfidf_NB = MultinomialNB()\n",
    "\n",
    "# Create the pipeline\n",
    "model_tfidf_NB = Pipeline([(\"vectorizer\", vectorizer_tfidf), (\"classifier\", classifier_tfidf_NB)])\n",
    "\n",
    "# Perform cross-validation\n",
    "cross_val_scores = cross_val_score(model_tfidf_NB, X_train, y_train, cv=6)\n",
    "\n",
    "# Print cross-validation scores\n",
    "print(\"Cross-validation scores for each fold:\", cross_val_scores)\n",
    "\n",
    "# Print the mean cross-validation score\n",
    "print(\"Mean cross-validation score:\", cross_val_scores.mean())\n",
    "\n",
    "# Train the model on the full training set\n",
    "model_tfidf_NB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Predict and evaluate the model on the test data\n",
    "predicted_test_nb = model_tfidf_NB.predict(X_test)\n",
    "accuracy_test_nb = accuracy_score(y_test, predicted_test_nb)\n",
    "print('Accuracy Test data for NB model: {:.1%}'.format(accuracy_test_nb))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrice de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = confusion_matrix(y_test, predicted_test_nb)\n",
    "df_cm = pd.DataFrame(data, columns=np.unique(y_test), index = np.unique(y_test))\n",
    "df_cm.index.name = 'Actual'\n",
    "df_cm.columns.name = 'Predicted'\n",
    "\n",
    "\n",
    "f, ax = plt.subplots(figsize=(12, 12))\n",
    "cmap = sns.cubehelix_palette(light=1, as_cmap=True)\n",
    "\n",
    "sns.heatmap(df_cm, cbar=False, annot=True, cmap=cmap, square=True, fmt='.0f',\n",
    "            annot_kws={'size': 18})\n",
    "plt.title('Actuals vs Predicted')\n",
    "\n",
    "# Save the plot as a PNG file\n",
    "plt.savefig('Result/country/MachineLearning/NB/confusion_matrix.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier (RFC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the number of samples to select for training and testing\n",
    "samples_for_train = 9000\n",
    "samples_for_test = 700\n",
    "\n",
    "# Initialize the DataFrames for training and testing\n",
    "train_RF = pd.DataFrame()\n",
    "test_RF = pd.DataFrame()\n",
    "\n",
    "# Loop through each unique dialect\n",
    "for dialect in train['dialect'].unique():\n",
    "    # Select samples for training\n",
    "    train_dialect = train[train['dialect'] == dialect].sample(samples_for_train, random_state=42)\n",
    "    train_RF = pd.concat([train_RF, train_dialect])\n",
    "\n",
    "    # Select samples for testing\n",
    "    test_dialect = test[test['dialect'] == dialect].sample(samples_for_test, random_state=42)\n",
    "    test_RF = pd.concat([test_RF, test_dialect])\n",
    "\n",
    "# Ensure that the data is shuffled\n",
    "train_RF = train_RF.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "test_RF = test_RF.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Display information about the new DataFrames\n",
    "print(\"train_RF shape:\", train_RF.shape)\n",
    "print(\"test_RF shape:\", test_RF.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_RF = train_RF['text']\n",
    "y_train_RF = train_RF['dialect']\n",
    "X_test_RF = test_RF['text']\n",
    "y_test_RF = test_RF['dialect']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization (TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "corpus = X_train_RF\n",
    "# Initizalize the vectorizer with max nr words and ngrams (1: single words, 2: two words in a row)\n",
    "vectorizer_tfidf = TfidfVectorizer(ngram_range=(1,3))\n",
    "# Fit the vectorizer to the training data\n",
    "vectorizer_tfidf.fit(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Create the Random Forest classifier\n",
    "classifier_tfidf_RF = RandomForestClassifier(n_estimators=25)\n",
    "\n",
    "# Create the pipeline with the Tfidf vectorizer\n",
    "model_tfidf_RF = Pipeline([(\"vectorizer\", TfidfVectorizer()), (\"classifier\", classifier_tfidf_RF)])\n",
    "\n",
    "# Set verbose mode for the classifier\n",
    "model_tfidf_RF.named_steps['classifier'].verbose = 1\n",
    "\n",
    "# Use cross_val_score to perform cross-validation\n",
    "cross_val_scores = cross_val_score(model_tfidf_RF, X_train_RF, y_train_RF, cv=6)  # 6 folds\n",
    "\n",
    "# Display the cross-validation scores for each fold\n",
    "print(\"Cross-validation scores for each fold:\", cross_val_scores)\n",
    "\n",
    "# Display the average cross-validation score\n",
    "print(\"Average cross-validation score:\", cross_val_scores.mean())\n",
    "\n",
    "# Train the model on the complete training set\n",
    "model_tfidf_RF.fit(X_train_RF, y_train_RF)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "predicted_test_tfidf_RF = model_tfidf_RF.predict(X_test_RF)\n",
    "accuracy_test_tfidf_RF = accuracy_score(y_test_RF, predicted_test_tfidf_RF)\n",
    "print('Accuracy Test data for RF model: {:.1%}'.format(accuracy_test_tfidf_RF))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrice de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = confusion_matrix(y_test_RF, predicted_test_tfidf_RF)\n",
    "df_cm = pd.DataFrame(data, columns=np.unique(y_test_RF), index = np.unique(y_test_RF))\n",
    "df_cm.index.name = 'Actual'\n",
    "df_cm.columns.name = 'Predicted'\n",
    "\n",
    "\n",
    "f, ax = plt.subplots(figsize=(12, 12))\n",
    "cmap = sns.cubehelix_palette(light=1, as_cmap=True)\n",
    "\n",
    "sns.heatmap(df_cm, cbar=False, annot=True, cmap=cmap, square=True, fmt='.0f',\n",
    "            annot_kws={'size': 18})\n",
    "plt.title('Actuals vs Predicted')\n",
    "\n",
    "# Save the plot as a PNG file\n",
    "plt.savefig('Result/country/MachineLearning/RandomForest/confusion_matrix.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Classifier (LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the number of samples to select for training and testing\n",
    "samples_for_train = 9000\n",
    "samples_for_test = 700\n",
    "\n",
    "# Initialize the DataFrames train_LR and test_LR\n",
    "train_LR = pd.DataFrame()\n",
    "test_LR = pd.DataFrame()\n",
    "\n",
    "# Loop through each dialect\n",
    "for dialect in train['dialect'].unique():\n",
    "    # Select samples for training\n",
    "    train_dialect = train[train['dialect'] == dialect].sample(samples_for_train, random_state=42)\n",
    "    train_LR = pd.concat([train_LR, train_dialect])\n",
    "\n",
    "    # Select samples for testing\n",
    "    test_dialect = test[test['dialect'] == dialect].sample(samples_for_test, random_state=42)\n",
    "    test_LR = pd.concat([test_LR, test_dialect])\n",
    "\n",
    "# Ensure that the data is shuffled\n",
    "train_LR = train_LR.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "test_LR = test_LR.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Display the shapes of the new DataFrames\n",
    "print(\"train_LR shape:\", train_LR.shape)\n",
    "print(\"test_LR shape:\", test_LR.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_LR = train_LR['text']\n",
    "y_train_LR = train_LR['dialect']\n",
    "X_test_LR = test_LR['text']\n",
    "y_test_LR = test_LR['dialect']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization (TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "corpus = X_train_LR\n",
    "# Initizalize the vectorizer with max nr words and ngrams (1: single words, 2: two words in a row)\n",
    "vectorizer_tfidf = TfidfVectorizer(ngram_range=(1,3))\n",
    "# Fit the vectorizer to the training data\n",
    "vectorizer_tfidf.fit(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Initialize the Logistic Regression classifier\n",
    "classifier_tfidf_LR = LogisticRegression()\n",
    "\n",
    "# Create the pipeline with the Tfidf vectorizer and the Logistic Regression classifier\n",
    "model_tfidf_LR = Pipeline([(\"vectorizer\", TfidfVectorizer()), (\"classifier\", classifier_tfidf_LR)])\n",
    "\n",
    "# Set verbose mode for the classifier to show progress\n",
    "model_tfidf_LR.named_steps['classifier'].verbose = 1\n",
    "\n",
    "# Use cross_val_score to perform cross-validation\n",
    "cross_val_scores_LR = cross_val_score(model_tfidf_LR, X_train_LR, y_train_LR, cv=6)  # 6-fold cross-validation\n",
    "\n",
    "# Display the cross-validation scores for each fold\n",
    "print(\"Cross-validation scores for each fold:\", cross_val_scores_LR)\n",
    "\n",
    "# Display the average score from cross-validation\n",
    "print(\"Average cross-validation score:\", cross_val_scores_LR.mean())\n",
    "\n",
    "# Train the model on the complete training set\n",
    "model_tfidf_LR.fit(X_train_LR, y_train_LR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "predicted_test_tfidf_LR = model_tfidf_LR.predict(X_test_LR)\n",
    "accuracy_test_tfidf_LR = accuracy_score(y_test_LR, predicted_test_tfidf_LR)\n",
    "print('Accuracy Test data for LR model: {:.1%}'.format(accuracy_test_tfidf_LR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrice de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = confusion_matrix(y_test_LR, predicted_test_tfidf_LR)\n",
    "df_cm = pd.DataFrame(data, columns=np.unique(y_test_LR), index = np.unique(y_test_LR))\n",
    "df_cm.index.name = 'Actual'\n",
    "df_cm.columns.name = 'Predicted'\n",
    "\n",
    "\n",
    "f, ax = plt.subplots(figsize=(12, 12))\n",
    "cmap = sns.cubehelix_palette(light=1, as_cmap=True)\n",
    "\n",
    "sns.heatmap(df_cm, cbar=False, annot=True, cmap=cmap, square=True, fmt='.0f',\n",
    "            annot_kws={'size': 18})\n",
    "plt.title('Actuals vs Predicted')\n",
    "\n",
    "# Save the plot as a PNG file\n",
    "plt.savefig('Result/country/MachineLearning/LogisticRegression/confusion_matrix.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors Classifier (KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the number of samples you want to select for training and testing\n",
    "samples_for_train = 9000\n",
    "samples_for_test = 700\n",
    "\n",
    "# Initialize the DataFrames train_knn and test_knn\n",
    "train_knn = pd.DataFrame()\n",
    "test_knn = pd.DataFrame()\n",
    "\n",
    "# Loop through each dialect\n",
    "for dialect in train['dialect'].unique():\n",
    "    # Select samples for training\n",
    "    train_dialect = train[train['dialect'] == dialect].sample(samples_for_train, random_state=42)\n",
    "    train_knn = pd.concat([train_knn, train_dialect])\n",
    "\n",
    "    # Select samples for testing\n",
    "    test_dialect = test[test['dialect'] == dialect].sample(samples_for_test, random_state=42)\n",
    "    test_knn = pd.concat([test_knn, test_dialect])\n",
    "\n",
    "# Ensure data is shuffled\n",
    "train_knn = train_knn.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "test_knn = test_knn.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Display information about the new DataFrames\n",
    "print(\"train_knn shape:\", train_knn.shape)\n",
    "print(\"test_knn shape:\", test_knn.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and labels\n",
    "X_train_knn = train_knn['text']\n",
    "y_train_knn = train_knn['dialect']\n",
    "X_test_knn = test_knn['text']\n",
    "y_test_knn = test_knn['dialect']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vectorization (TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "corpus = X_train_knn\n",
    "# Initizalize the vectorizer with max nr words and ngrams (1: single words, 2: two words in a row)\n",
    "vectorizer_tfidf_knn = TfidfVectorizer(ngram_range=(1,3))\n",
    "# Fit the vectorizer to the training data\n",
    "vectorizer_tfidf_knn.fit(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "classifier_tfidf_knn = KNeighborsClassifier(n_neighbors=18)  \n",
    "\n",
    "# Create the pipeline for KNN\n",
    "model_tfidf_knn = Pipeline([(\"vectorizer\", vectorizer_tfidf_knn), (\"classifier\", classifier_tfidf_knn)])\n",
    "# Fit with a progress bar\n",
    "model_tfidf_knn.named_steps['classifier'].verbose = 1\n",
    "\n",
    "# Cross-validation for KNN\n",
    "cross_val_scores_knn = cross_val_score(model_tfidf_knn, X_train_knn, y_train_knn, cv=6)\n",
    "\n",
    "# Display cross-validation scores\n",
    "print(\"Cross-validation scores for each fold:\", cross_val_scores_knn)\n",
    "\n",
    "# Display the average score\n",
    "print(\"Average cross-validation score:\", cross_val_scores_knn.mean())\n",
    "\n",
    "# Train the KNN model on the entire training set\n",
    "model_tfidf_knn.fit(X_train_knn, y_train_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Make predictions on the test set\n",
    "predicted_test_tfidf_knn = model_tfidf_knn.predict(X_test_knn)\n",
    "accuracy_test_tfidf_knn = accuracy_score(y_test_knn, predicted_test_tfidf_knn)\n",
    "print('Accuracy on test data: {:.1%}'.format(accuracy_test_tfidf_knn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrice de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "data_knn = confusion_matrix(y_test_knn, predicted_test_tfidf_knn)\n",
    "df_cm_knn = pd.DataFrame(data_knn, columns=np.unique(y_test_knn), index=np.unique(y_test_knn))\n",
    "df_cm_knn.index.name = 'Actual'\n",
    "df_cm_knn.columns.name = 'Predicted'\n",
    "\n",
    "# Plot the confusion matrix\n",
    "f_knn, ax_knn = plt.subplots(figsize=(12, 12))\n",
    "cmap_knn = sns.cubehelix_palette(light=1, as_cmap=True)\n",
    "\n",
    "sns.heatmap(df_cm_knn, cbar=False, annot=True, cmap=cmap_knn, square=True, fmt='.0f',\n",
    "            annot_kws={'size': 18})\n",
    "plt.title('Actuals vs Predicted (KNN)')\n",
    "\n",
    "# Save the plot as a PNG file\n",
    "plt.savefig('Result/country/MachineLearning/KNN/confusion_matrix.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine Classifier (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the number of samples you want to select for training and testing\n",
    "samples_for_train = 9000\n",
    "samples_for_test = 700\n",
    "\n",
    "# Initialize the DataFrames train_svm and test_svm\n",
    "train_svm = pd.DataFrame()\n",
    "test_svm = pd.DataFrame()\n",
    "\n",
    "# Loop through each dialect\n",
    "for dialect in train['dialect'].unique():\n",
    "    # Select samples for training\n",
    "    train_dialect = train[train['dialect'] == dialect].sample(samples_for_train, random_state=42)\n",
    "    train_svm = pd.concat([train_svm, train_dialect])\n",
    "\n",
    "    # Select samples for testing\n",
    "    test_dialect = test[test['dialect'] == dialect].sample(samples_for_test, random_state=42)\n",
    "    test_svm = pd.concat([test_svm, test_dialect])\n",
    "\n",
    "# Ensure data is shuffled\n",
    "train_svm = train_svm.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "test_svm = test_svm.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Display information about the new DataFrames\n",
    "print(\"train_svm shape:\", train_svm.shape)\n",
    "print(\"test_svm shape:\", test_svm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_svm = train_svm['text']\n",
    "y_train_svm = train_svm['dialect']\n",
    "X_test_svm = test_svm['text']\n",
    "y_test_svm = test_svm['dialect']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization (TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "corpus = X_train_svm\n",
    "# Initizalize the vectorizer with max nr words and ngrams (1: single words, 2: two words in a row)\n",
    "vectorizer_tfidf_svm = TfidfVectorizer(ngram_range=(1,3))\n",
    "# Fit the vectorizer to the training data\n",
    "vectorizer_tfidf_svm.fit(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "classifier_tfidf_svm = SVC(kernel='linear') \n",
    "\n",
    "# Create the pipeline\n",
    "model_tfidf_svm = Pipeline([(\"vectorizer\", vectorizer_tfidf_svm), (\"classifier\", classifier_tfidf_svm)])\n",
    "\n",
    "# Fit with a progress bar (verbose)\n",
    "model_tfidf_svm.named_steps['classifier'].verbose = 1\n",
    "\n",
    "# Use cross_val_score for cross-validation\n",
    "cross_val_scores_svm = cross_val_score(model_tfidf_svm, X_train_svm, y_train_svm, cv=6)  \n",
    "\n",
    "# Display cross-validation scores\n",
    "print(\"Cross-validation scores for each fold:\", cross_val_scores_svm)\n",
    "\n",
    "# Display the mean score\n",
    "print(\"Mean cross-validation score:\", cross_val_scores_svm.mean())\n",
    "\n",
    "# Train the model on the complete training set\n",
    "model_tfidf_svm.fit(X_train_svm, y_train_svm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Make predictions on the test set\n",
    "predicted_test_tfidf_svm = model_tfidf_svm.predict(X_test_svm)\n",
    "accuracy_test_tfidf_svm = accuracy_score(y_test_svm, predicted_test_tfidf_svm)\n",
    "print('Accuracy on test data: {:.1%}'.format(accuracy_test_tfidf_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrice de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Confusion matrix\n",
    "data_svm = confusion_matrix(y_test_svm, predicted_test_tfidf_svm)\n",
    "df_cm_svm = pd.DataFrame(data_svm, columns=np.unique(y_test_svm), index=np.unique(y_test_svm))\n",
    "df_cm_svm.index.name = 'Actual'\n",
    "df_cm_svm.columns.name = 'Predicted'\n",
    "\n",
    "# Plot the confusion matrix\n",
    "f_svm, ax_svm = plt.subplots(figsize=(12, 12))\n",
    "cmap_svm = sns.cubehelix_palette(light=1, as_cmap=True)\n",
    "\n",
    "sns.heatmap(df_cm_svm, cbar=False, annot=True, cmap=cmap_svm, square=True, fmt='.0f',\n",
    "            annot_kws={'size': 18})\n",
    "plt.title('Actuals vs Predicted (SVM)')\n",
    "\n",
    "# Save the plot as a PNG file\n",
    "plt.savefig('Result/country/MachineLearning/SVM/confusion_matrix.png')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Define the directories where you want to save the models\n",
    "save_directory_nb = \"Model/country/MachineLearning/NB/\"\n",
    "save_directory_rf = \"Model/country/MachineLearning/RandomForest/\"\n",
    "save_directory_lr = \"Model/country/MachineLearning/LogisticRegression/\"\n",
    "save_directory_knn = \"Model/country/MachineLearning/KNN/\"\n",
    "save_directory_svm = \"Model/country/MachineLearning/SVM/\"\n",
    "\n",
    "# Save the models using joblib\n",
    "joblib.dump(model_tfidf_NB, save_directory_nb + 'ArabicDialectClassificationNB.pkl')\n",
    "joblib.dump(model_tfidf_RF, save_directory_rf + 'ArabicDialectClassificationRF.pkl')\n",
    "joblib.dump(model_tfidf_LR, save_directory_lr + 'ArabicDialectClassificationLR.pkl')\n",
    "joblib.dump(model_tfidf_knn, save_directory_knn + 'ArabicDialectClassificationKNN.pkl')\n",
    "joblib.dump(model_tfidf_svm, save_directory_svm + 'ArabicDialectClassificationSVM.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arabert Model (BERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "\n",
    "    # Tell PyTorch to use the GPU.\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_label={\n",
    "    'EG':0,\n",
    "    'SY':1,\n",
    "    'PL':2,\n",
    "    'KW':3,\n",
    "    'LB':4,\n",
    "    'LY':5,\n",
    "    'JO':6,\n",
    "    'DZ':7,\n",
    "    'QA':8,\n",
    "    'AE':9,\n",
    "    'BH':10,\n",
    "    'SA':11,\n",
    "    'OM':12,\n",
    "    'MA':13,\n",
    "    'IQ':14,\n",
    "    'TN':15,\n",
    "    'SD':16,\n",
    "    'YE':17,\n",
    "    'MSA':18\n",
    "}\n",
    "label_map={\n",
    "    0:'EG',\n",
    "    1:'SY',\n",
    "    2:'PL',\n",
    "    3:'KW',\n",
    "    4:'LB',\n",
    "    5:'LY',\n",
    "    6:'JO',\n",
    "    7:'DZ',\n",
    "    8:'QA',\n",
    "    9:'AE',\n",
    "    10:'BH',\n",
    "    11:'SA',\n",
    "    12:'OM',\n",
    "    13:'MA',\n",
    "    14:'IQ',\n",
    "    15:'TN',\n",
    "    16:'SD',\n",
    "    17:'YE',\n",
    "    18:'MSA'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The data is preprocessed already , Don t need to do it again otherwise it will take a lot of time to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from arabert.preprocess import ArabertPreprocessor\n",
    "#model_name=\"bert-base-arabert\"\n",
    "#arabert_prep = ArabertPreprocessor(model_name=model_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"Data\\country\\preprocessed_data/dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset[\"text\"]=dataset[\"text\"].apply(lambda x:arabert_prep.preprocess(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"Data\\country\\preprocessed_data/preprocessed_dataset_araberta.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Group the DataFrame by dialect\n",
    "grouped_df = dataset.groupby('dialect')\n",
    "\n",
    "# Initialize the training and test DataFrames\n",
    "train = pd.DataFrame()\n",
    "test = pd.DataFrame()\n",
    "\n",
    "# For each group (dialect), split the data into training and test sets\n",
    "for group_name, group_data in grouped_df:\n",
    "    train_data, test_data = train_test_split(group_data, test_size=0.2, random_state=42)\n",
    "    train = pd.concat([train, train_data])\n",
    "    test = pd.concat([test, test_data])\n",
    "\n",
    "# Reset the index of the resulting DataFrames\n",
    "train = train.reset_index(drop=True)\n",
    "test = test.reset_index(drop=True)\n",
    "\n",
    "# Display the first few rows of the resulting DataFrames\n",
    "print(\"Train DataFrame:\")\n",
    "print(train.head())\n",
    "\n",
    "print(\"\\nTest DataFrame:\")\n",
    "print(test.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arabert.preprocess import ArabertPreprocessor\n",
    "from sklearn.metrics import (accuracy_score, f1_score,recall_score)\n",
    "from torch.utils.data import  Dataset\n",
    "from transformers import (AutoConfig, AutoModelForSequenceClassification,\n",
    "                        AutoTokenizer, BertTokenizer, Trainer,\n",
    "                        TrainingArguments)\n",
    "from transformers.data.processors.utils import InputFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chose bert model\n",
    "model_name = 'aubmindlab/bert-base-arabert'\n",
    "\n",
    "num_labels = 19\n",
    "max_length = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationDataset(Dataset):\n",
    "    def __init__(self, text, target, model_name, max_len, label_map):\n",
    "      super(ClassificationDataset).__init__()\n",
    "\n",
    "      self.text = text\n",
    "      self.target = target\n",
    "      self.tokenizer_name = model_name\n",
    "      self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "      self.max_len = max_len\n",
    "      self.label_map = label_map\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "      return len(self.text)\n",
    "\n",
    "    def __getitem__(self,item):\n",
    "      text = str(self.text[item])\n",
    "      text = \" \".join(text.split())\n",
    "\n",
    "      inputs = self.tokenizer(\n",
    "          text,\n",
    "          max_length=self.max_len,\n",
    "          padding='max_length',\n",
    "          truncation=True\n",
    "        )\n",
    "      return InputFeatures(**inputs,label= self.target[item])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping and splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['dialect'] = train['dialect'].map(map_label)\n",
    "test['dialect'] = test['dialect'].map(map_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train[train['dialect'].isnull()==False]\n",
    "test=test[test['dialect'].isnull()==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 120\n",
    "train_dataset = ClassificationDataset(\n",
    "    train['text'].to_list(),\n",
    "    train['dialect'].to_list(),\n",
    "    model_name,\n",
    "    max_len,\n",
    "    map_label\n",
    ")\n",
    "test_dataset = ClassificationDataset(\n",
    "    test['text'].to_list(),\n",
    "    test['dialect'].to_list(),\n",
    "    model_name,\n",
    "    max_len,\n",
    "    map_label\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init():\n",
    "    return AutoModelForSequenceClassification.from_pretrained(model_name, return_dict=True, num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p): #p should be of type EvalPrediction\n",
    "  preds = np.argmax(p.predictions, axis=1)\n",
    "  assert len(preds) == len(p.label_ids)\n",
    "  macro_f1 = f1_score(p.label_ids,preds,average='macro')\n",
    "  macro_recall = recall_score(p.label_ids,preds,average='macro')\n",
    "  acc = accuracy_score(p.label_ids,preds)\n",
    "  return {\n",
    "      'macro_f1' : macro_f1,\n",
    "      'accuracy': acc,\n",
    "      'recall':macro_recall\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "from accelerate import Accelerator\n",
    "\n",
    "# Utilisez Accelator to configure the auto acceleration\n",
    "accelerator = Accelerator()\n",
    "\n",
    "# Utilisez TrainingArguments de la bibliothèque transformers\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./train\",\n",
    "    adam_epsilon=1e-8,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=15,\n",
    "    warmup_ratio=0,\n",
    "    do_eval=True,\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    save_total_limit=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='eval_loss',\n",
    "    greater_is_better=False,\n",
    "    report_to=[]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model = model_init(),\n",
    "    args = training_args,\n",
    "    train_dataset = train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#you can chose the model from checkpoint\n",
    "trainer.model.config.label2id = map_label\n",
    "trainer.model.config.id2label = label_map\n",
    "trainer.save_model(\"./model\")\n",
    "train_dataset.tokenizer.save_pretrained(\"./model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LTSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv(\"Data\\country\\preprocessed_data/dataset.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_words_removal(text, lst_words):\n",
    "    lst_text = text.split()\n",
    "    if lst_words is not None:\n",
    "        lst_text = [word for word in lst_text if word not in lst_words]\n",
    "    text = \" \".join(lst_text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrds = ['مع','لا','على','من','ما','في','الي','هو','انا','أنا','اله']\n",
    "dataset[\"text_clean\"] = dataset[\"text\"].apply(lambda x: freq_words_removal(x, wrds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#Shuffle the dataset\n",
    "dataset = dataset.reindex(np.random.permutation(dataset.index))\n",
    "dataset['LABEL'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "#One-hot encode the lab\n",
    "dataset.loc[dataset['dialect'] == 'SA', 'LABEL'] = 0\n",
    "dataset.loc[dataset['dialect'] == 'QA', 'LABEL'] = 1\n",
    "dataset.loc[dataset['dialect'] == 'KW', 'LABEL'] = 2\n",
    "dataset.loc[dataset['dialect'] == 'AE', 'LABEL'] = 3\n",
    "dataset.loc[dataset['dialect'] == 'OM', 'LABEL'] = 4\n",
    "dataset.loc[dataset['dialect'] == 'JO', 'LABEL'] = 5\n",
    "dataset.loc[dataset['dialect'] == 'PL', 'LABEL'] = 6\n",
    "dataset.loc[dataset['dialect'] == 'BH', 'LABEL'] = 7\n",
    "dataset.loc[dataset['dialect'] == 'LY', 'LABEL'] = 8\n",
    "dataset.loc[dataset['dialect'] == 'EG', 'LABEL'] = 9\n",
    "dataset.loc[dataset['dialect'] == 'SD', 'LABEL'] = 10\n",
    "dataset.loc[dataset['dialect'] == 'IQ', 'LABEL'] = 11\n",
    "dataset.loc[dataset['dialect'] == 'LB', 'LABEL'] = 12\n",
    "dataset.loc[dataset['dialect'] == 'SY', 'LABEL'] = 13\n",
    "dataset.loc[dataset['dialect'] == 'TN', 'LABEL'] = 14\n",
    "dataset.loc[dataset['dialect'] == 'DZ', 'LABEL'] = 15\n",
    "dataset.loc[dataset['dialect'] == 'MA', 'LABEL'] = 16\n",
    "dataset.loc[dataset['dialect'] == 'YE', 'LABEL'] = 17\n",
    "dataset.loc[dataset['dialect'] == 'MSA', 'LABEL'] = 18\n",
    "print(dataset['LABEL'][:10])\n",
    "labels = to_categorical(dataset['LABEL'], num_classes=19)\n",
    "print(labels[:10])\n",
    "if 'dialect' in dataset.keys():\n",
    "    dataset.drop(['dialect'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "n_most_common_words = 20000\n",
    "max_len = 250\n",
    "tokenizer = Tokenizer(num_words=n_most_common_words, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "tokenizer.fit_on_texts(dataset['text_clean'].values)\n",
    "sequences = tokenizer.texts_to_sequences(dataset['text_clean'].values)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "X = pad_sequences(sequences, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X , labels, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "emb_dim = 128\n",
    "batch_size = 256\n",
    "labels[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for device in gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)\n",
    "\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "\n",
    "print((X_train.shape, y_train.shape, X_test.shape, y_test.shape))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(n_most_common_words, emb_dim, input_length=X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.7))\n",
    "model.add(LSTM(64, dropout=0.7, recurrent_dropout=0.7))\n",
    "model.add(Dense(19, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,validation_split=0.2,callbacks=[EarlyStopping(monitor='val_loss',patience=6, min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accr = model.evaluate(X_test,y_test)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = [\"ما قبل البرنامج شي ترسخ في ذهنكم بأن مروان مراوغ وعنده مسألة إقناع هذا شي غلط الي شاهدته هو هروب ودفاع مستميت وإصرار على أن ما تحق هو نجاح\"]\n",
    "seq = tokenizer.texts_to_sequences(txt)\n",
    "padded = pad_sequences(seq, maxlen=max_len)\n",
    "pred = model.predict(padded)\n",
    "labels = ['SA','QA','KW','AE','OM','JO','PL','BH','LY','EG','SD','IQ','LB','SY','TN','DZ','MA','YE','MSA']\n",
    "print(pred, labels[np.argmax(pred)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
